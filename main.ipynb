{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 32-bit",
   "metadata": {
    "interpreter": {
     "hash": "14ba8550e4b5297708c8210aad8b33fb7581226caaa50346e28971de3ff05e1f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# CS-2376 Apriori Algorithm\n",
    "### Team Members\n",
    "1. Jenish Raj Bajracharya\n",
    "2. Nidup Dorji\n",
    "3. Satpreet Makhija\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "from itertools import combinations\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataframe = pd.read_csv(\"dataset/tesco2.csv\", header=None)\n",
    "# # dataframe.head()\n",
    "# dataframe = dataframe.values\n",
    "\n",
    "# data = set()\n",
    "# for items in dataframe:\n",
    "#     for sub_item in items:\n",
    "#         data.add(sub_item)\n",
    "\n",
    "\n",
    "# min_support = int(input(\"Enter support \"))\n",
    "# min_confidence = float(input(\"Enter confidence level \"))\n",
    "# data\n",
    "# unique_data = list(data)\n",
    "# print(unique_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_support = int(input(\"Enter support \"))\n",
    "min_confidence = float(input(\"Enter confidence level \"))\n",
    "\n",
    "\n",
    "data = set()\n",
    "dataframe = []\n",
    "transactions = 0\n",
    "total_item = 0\n",
    "with open('dataset/tesco2.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        dataframe.append(row)\n",
    "        transactions += 1\n",
    "        for item in row:\n",
    "            data.add(item)\n",
    "            total_item += 1\n",
    "\n",
    "\n",
    "## This cell reads file, and stores unique values from the transaction into data\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This section makes a list of frequent-1 itemsets which are greater than the minimum support the user enters\n",
    "def get_frequent_1_set(min_support, dataframe, data):\n",
    "    temp_data = dict()\n",
    "    itemset = data\n",
    "    for i in itemset:\n",
    "        count = 0\n",
    "        for d in dataframe:\n",
    "            if i in d:\n",
    "                count += 1\n",
    "        temp_data[i] = count\n",
    "        if temp_data[i] < min_support:\n",
    "            temp_data.pop(i)\n",
    "    # return list(temp_data.keys())\n",
    "    return sorted(temp_data.keys(), key=operator.itemgetter(0))\n",
    "\n",
    "\n",
    "# def get_item_combination():\n",
    "F1 = get_frequent_1_set(min_support, dataframe, data) \n",
    "# print(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## returns the combinations of a specific size\n",
    "def generate_candidate(array, size): # L1 is a list from get_freauent_set\n",
    "    return sum([list(map(set, combinations(array, size)))], [])\n",
    "  \n",
    "# print(generate_candidate(F1,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using the apriori property generates candidate set of size k (ck) using frequent k-1(Fk_1) itmeset\n",
    "# Lk_1 = [['apple', 'beer'], ['apple', 'rice'], ['beer', 'chicken'], ['beer', 'milk'], ['beer', 'rice'], ['chicken', 'rice'], ['milk', 'rice']]\n",
    "def apriori(Fk_1, k):\n",
    "    ck = [] \n",
    "    for i in Fk_1:\n",
    "       \n",
    "        for j in Fk_1:\n",
    "           \n",
    "            index = 0\n",
    "            buffer = []\n",
    "            if i == j:\n",
    "                pass\n",
    "            else:\n",
    "                while k-1 > index:\n",
    "                    if i[index] == j[index]:\n",
    "                        index += 1\n",
    "                    else:\n",
    "                        break\n",
    "                else:\n",
    "                    if i[k-1] > j[k-1]:\n",
    "                        \n",
    "                        for item in i:\n",
    "                            buffer.append(item)\n",
    "                        buffer.append(j[k-1])\n",
    "                        check = generate_candidate(buffer, k)\n",
    "                        count = 0\n",
    "                        for c in check:\n",
    "                            sorting = sorted(c)\n",
    "                            if list(sorting) in Fk_1:\n",
    "                                count += 1\n",
    "                        if count == len(check):\n",
    "                            ck.append(sorted(buffer))\n",
    "                           \n",
    "    return ck\n",
    "                        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## returns frequent (Fk) itemset for all k using the apriori module defined previously.\n",
    "def get_frequent_set(min_support, dataframe):\n",
    "    F1 = get_frequent_1_set(min_support, dataframe, data)\n",
    "    Fk_1 = []\n",
    "    for item in F1:\n",
    "        buffer = []\n",
    "        buffer.append(item)\n",
    "        Fk_1.append(buffer)\n",
    "    print(\"                                              Frequent 1 Itemset\")\n",
    "    print(Fk_1)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    all_frequent_item = dict()\n",
    "    k = 1\n",
    "    while len(Fk_1) != 0:\n",
    "     \n",
    "        ck = apriori(Fk_1, k)\n",
    "        Fk = []\n",
    "\n",
    "        for c in ck:\n",
    "            count = 0\n",
    "            candidate = set(c)\n",
    "            for d in dataframe:\n",
    "                if candidate.issubset(d):\n",
    "                    count += 1\n",
    "            if count >= min_support:\n",
    "                sorting = sorted(candidate)\n",
    "                Fk.append(sorting)\n",
    "                all_frequent_item[tuple(c)] = count\n",
    "        if Fk == []:\n",
    "            print(\"                                              Frequent {} Itemset\".format(k+1))\n",
    "            print(\"None\")\n",
    "            print(\"\\n\")\n",
    "        else:\n",
    "            print(\"                                              Frequent {} Itemset\".format(k+1))\n",
    "            print(Fk)\n",
    "            print(\"\\n\")\n",
    "        Fk_1 = []\n",
    "        k += 1\n",
    "      \n",
    "        for item in Fk:\n",
    "            Fk_1.append(item)\n",
    "        \n",
    "    return(all_frequent_item)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generates all association rule form frquent_item (i.e list with all the frequnt item includes everything from size 0 to k )\n",
    "def get_association_rule():\n",
    "    frequent_item = get_frequent_set(min_support, dataframe)\n",
    "    count = 0\n",
    "    rule_count = 0\n",
    "    print(\"                                                 Data Summary\")\n",
    "\n",
    "    print(\"Min Support = {} \\nConfidence = {:.2f} % \\nTransactions = {} \\nItems = {}\\n\".format(min_support, min_confidence, transactions, total_item))\n",
    "    print(\"                                              Association Rules\")\n",
    "    for item in frequent_item:\n",
    "        count = 1\n",
    "        # print(\"item : {}\".format(item))\n",
    "        sup_b = frequent_item[item]\n",
    "        # print(item)\n",
    "        while count < len(item):\n",
    "            combo = generate_candidate(item,count)  # give us the possible combinations for item\n",
    "            # print(\"combo : {}\".format(combo))\n",
    "            count = count + 1\n",
    "            for c in combo:\n",
    "                a = []\n",
    "                sup_a = 0\n",
    "               \n",
    "                \n",
    "                for i in c:\n",
    "                    a.append(i)\n",
    "                for data in dataframe:\n",
    "                        if set(a).issubset(data):\n",
    "                            sup_a = sup_a + 1 \n",
    "                 \n",
    "                confidence = 100*sup_b/sup_a\n",
    "                b = []\n",
    "\n",
    "                if confidence >= min_confidence:\n",
    "                    for sub_item in item: \n",
    "                        # print(\"a: {}\".format(a))\n",
    "                        # print(\"subitem: {}\".format(sub_item))\n",
    "                        if sub_item not in a:\n",
    "                            b.append(sub_item)\n",
    "                        # print(\"b : {}\".format(b))\n",
    "                    rule_count = rule_count + 1\n",
    "                    \n",
    "                    print(\"================== Rule {} =============================\".format(rule_count))\n",
    "                    print (\" {} ==> {}\".format(a,b))\n",
    "                    print(\"Support = {}\".format(sup_b))\n",
    "                    print(\"Condidence = {:0.2f} %\".format(confidence))\n",
    "                    print(\"\\n\")\n",
    "                   \n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                              Frequent 1 Itemset\n[['Butter'], ['Coffee Powder'], ['Cheese'], ['Ghee'], ['Milk'], ['Panner'], ['Sweet'], ['Sugar'], ['Tea Powder'], ['apple'], ['beer'], ['milk'], ['rice']]\n\n\n                                              Frequent 2 Itemset\n[['Butter', 'Cheese'], ['Ghee', 'Panner'], ['Sugar', 'Sweet'], ['Butter', 'Tea Powder'], ['Cheese', 'Tea Powder'], ['Panner', 'Tea Powder'], ['apple', 'beer'], ['beer', 'milk'], ['beer', 'rice']]\n\n\n                                              Frequent 3 Itemset\n[['Butter', 'Cheese', 'Tea Powder']]\n\n\n                                              Frequent 4 Itemset\nNone\n\n\n                                                 Data Summary\nMin Support = 3 \nConfidence = 60.00 % \nTransactions = 20 \nItems = 69\n\n                                              Association Rules\n================== Rule 1 =============================\n ['Butter'] ==> ['Cheese']\nSupport = 5\nCondidence = 83.33 %\n\n\n================== Rule 2 =============================\n ['Cheese'] ==> ['Butter']\nSupport = 5\nCondidence = 100.00 %\n\n\n================== Rule 3 =============================\n ['Ghee'] ==> ['Panner']\nSupport = 3\nCondidence = 60.00 %\n\n\n================== Rule 4 =============================\n ['Panner'] ==> ['Ghee']\nSupport = 3\nCondidence = 60.00 %\n\n\n================== Rule 5 =============================\n ['Sugar'] ==> ['Sweet']\nSupport = 3\nCondidence = 100.00 %\n\n\n================== Rule 6 =============================\n ['Sweet'] ==> ['Sugar']\nSupport = 3\nCondidence = 75.00 %\n\n\n================== Rule 7 =============================\n ['Tea Powder'] ==> ['Butter']\nSupport = 3\nCondidence = 60.00 %\n\n\n================== Rule 8 =============================\n ['Cheese'] ==> ['Tea Powder']\nSupport = 3\nCondidence = 60.00 %\n\n\n================== Rule 9 =============================\n ['Tea Powder'] ==> ['Cheese']\nSupport = 3\nCondidence = 60.00 %\n\n\n================== Rule 10 =============================\n ['Panner'] ==> ['Tea Powder']\nSupport = 3\nCondidence = 60.00 %\n\n\n================== Rule 11 =============================\n ['Tea Powder'] ==> ['Panner']\nSupport = 3\nCondidence = 60.00 %\n\n\n================== Rule 12 =============================\n ['apple'] ==> ['beer']\nSupport = 3\nCondidence = 75.00 %\n\n\n================== Rule 13 =============================\n ['milk'] ==> ['beer']\nSupport = 3\nCondidence = 75.00 %\n\n\n================== Rule 14 =============================\n ['beer'] ==> ['rice']\nSupport = 4\nCondidence = 66.67 %\n\n\n================== Rule 15 =============================\n ['rice'] ==> ['beer']\nSupport = 4\nCondidence = 100.00 %\n\n\n================== Rule 16 =============================\n ['Cheese'] ==> ['Butter', 'Tea Powder']\nSupport = 3\nCondidence = 60.00 %\n\n\n================== Rule 17 =============================\n ['Tea Powder'] ==> ['Butter', 'Cheese']\nSupport = 3\nCondidence = 60.00 %\n\n\n================== Rule 18 =============================\n ['Cheese', 'Butter'] ==> ['Tea Powder']\nSupport = 3\nCondidence = 60.00 %\n\n\n================== Rule 19 =============================\n ['Tea Powder', 'Butter'] ==> ['Cheese']\nSupport = 3\nCondidence = 100.00 %\n\n\n================== Rule 20 =============================\n ['Tea Powder', 'Cheese'] ==> ['Butter']\nSupport = 3\nCondidence = 100.00 %\n\n\n"
     ]
    }
   ],
   "source": [
    "get_association_rule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}